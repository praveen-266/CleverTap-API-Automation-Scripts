{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request still in progress, please retry later. Retrying... Attempt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prave\\anaconda3\\envs\\python3.12.2\\Lib\\json\\decoder.py:353: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  calculated_Date                    Metric Name channel_name    count\n",
      "0      2024-08-31  30 - Days Unique Active Users     Hongkong      518\n",
      "1      2024-08-31  30 - Days Unique Active Users        India  9851358\n",
      "2      2024-08-31  30 - Days Unique Active Users    Indonesia     1108\n",
      "3      2024-08-31  30 - Days Unique Active Users     Malaysia   221759\n",
      "4      2024-08-31  30 - Days Unique Active Users  Middle East   891561\n",
      "5      2024-08-31  30 - Days Unique Active Users  Philippines   342997\n",
      "6      2024-08-31  30 - Days Unique Active Users    Singapore   277140\n",
      "7      2024-08-31  30 - Days Unique Active Users     Thailand      899\n",
      "8      2024-08-31  30 - Days Unique Active Users      Vietnam      548\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "MAX_RETRIES = 10\n",
    "RETRY_DELAY = 60  # Initial delay between retries in seconds\n",
    "MAX_RETRY_DELAY = 1000  # Maximum delay between retries\n",
    "\n",
    "# Get today's date\n",
    "end_date = datetime.now()\n",
    "# Calculate the start date (30 days before today)\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "output_file = r'C:\\Users\\prave\\1M_Active_Users_Summary_Data.xlsx'\n",
    "\n",
    "# Define the mapping dictionary\n",
    "mapping = {\n",
    "    'india': 'India',\n",
    "    'philippines': 'Philippines',\n",
    "    'malaysia': 'Malaysia',\n",
    "    'singapore': 'Singapore',\n",
    "    'gulf': 'Middle East',\n",
    "    'hongkong': 'Hongkong',\n",
    "    'thailand': 'Thailand',\n",
    "    'indonesia': 'Indonesia',\n",
    "    'vietnam': 'Vietnam',\n",
    "    'rexmonster': 'India',\n",
    "}\n",
    "\n",
    "# Define the required columns\n",
    "required_columns = [\n",
    "    'India', 'Philippines', 'Malaysia', 'Singapore', \n",
    "    'Middle East', 'Hongkong', 'Thailand', \n",
    "    'Indonesia', 'Vietnam',\n",
    "]\n",
    "\n",
    "async def fetch_event_data(session, start_date_integer, end_date_integer):\n",
    "    url = \"https://in1.api.clevertap.com/1/profiles.json?batch_size=5000&app=false&events=false\"\n",
    "    payload = json.dumps({\n",
    "        \"advanced_query\": {\n",
    "            \"did_any\": {\n",
    "                \"any_events\": [\n",
    "                    {\n",
    "                        \"event_name\": event, \n",
    "                        \"common_profile_properties\": {\n",
    "                            \"reachability\": [{\"name\": \"has_email\", \"value\": \"True\"}],\n",
    "                            \"user_properties\": [{\n",
    "                                \"name\": \"channel_name\", \n",
    "                                \"operator\": \"contains\", \n",
    "                                \"value\": [\"india\", \"philippines\", \"malaysia\", \n",
    "                                           \"singapore\", \"gulf\", \"hongkong\", \n",
    "                                           \"thailand\", \"indonesia\", \"vietnam\", \n",
    "                                           \"rexmonster\"]\n",
    "                            }]\n",
    "                        },\n",
    "                        \"from\": start_date_integer,\n",
    "                        \"to\": end_date_integer\n",
    "                    } for event in [\n",
    "                        \"App Launched\", \"Notification Viewed\", \n",
    "                        \"Email Opened\", \"MM Email Opened\", \n",
    "                        \"PageViewed\"\n",
    "                    ]\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    headers = {\n",
    "        'X-CleverTap-Account-Id': '**********',\n",
    "        'X-CleverTap-Passcode': '*********',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    retry_count = 0\n",
    "    retry_delay = RETRY_DELAY\n",
    "    unique_users = set() \n",
    "    count_country = {}\n",
    "\n",
    "    while retry_count < MAX_RETRIES:\n",
    "        async with session.post(url, headers=headers, data=payload) as response:\n",
    "            try:\n",
    "                response_json = await response.json()\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to decode JSON response. Retrying...\")\n",
    "                retry_count += 1\n",
    "                await asyncio.sleep(retry_delay)\n",
    "                retry_delay = min(retry_delay * 2, MAX_RETRY_DELAY)\n",
    "                continue\n",
    "\n",
    "            if response_json.get('status') == 'fail' and response_json.get('code') == 2:\n",
    "                retry_count += 1\n",
    "                print(f\"Request still in progress, please retry later. Retrying... Attempt {retry_count}\")\n",
    "                await asyncio.sleep(retry_delay)\n",
    "                retry_delay = min(retry_delay * 2, MAX_RETRY_DELAY)\n",
    "                continue\n",
    "            elif response_json.get('status') == 'fail':\n",
    "                print(f\"Failed request with error: {response_json.get('error')}\")\n",
    "                return {}, set()\n",
    "\n",
    "            cursor = response_json.get('cursor')\n",
    "            while cursor:\n",
    "                next_url = f\"https://in1.api.clevertap.com/1/profiles.json?cursor={cursor}\"\n",
    "                async with session.get(next_url, headers=headers) as response:\n",
    "                    response_json = await response.json()\n",
    "                    if response_json.get('status') == 'fail' and response_json.get('code') == 2:\n",
    "                        retry_count += 1\n",
    "                        print(f\"Request still in progress, please retry later. Retrying... Attempt {retry_count}\")\n",
    "                        await asyncio.sleep(RETRY_DELAY * retry_count)\n",
    "                        continue\n",
    "\n",
    "                    cursor = response_json.get('next_cursor')\n",
    "                    if 'records' in response_json:\n",
    "                        for record in response_json['records']:\n",
    "                            channel_name = record.get('profileData', {}).get('channel_name', None)\n",
    "                            user_id = record.get('identity')\n",
    "                            if user_id and user_id not in unique_users: \n",
    "                                unique_users.add(user_id)  \n",
    "                                if channel_name is not None:\n",
    "                                    if isinstance(channel_name, list):\n",
    "                                        channel_name = ', '.join(channel_name)\n",
    "                                    count_country[channel_name] = count_country.get(channel_name, 0) + 1\n",
    "\n",
    "                if not cursor:\n",
    "                    break\n",
    "\n",
    "            if count_country:\n",
    "                return count_country, unique_users\n",
    "            else:\n",
    "                retry_count += 1\n",
    "                print(f\"Retrying... Attempt {retry_count}\")\n",
    "                await asyncio.sleep(retry_delay)\n",
    "                retry_delay = min(retry_delay * 2, MAX_RETRY_DELAY)\n",
    "\n",
    "    print(\"Max retries reached. Unable to fetch data.\")\n",
    "    return {}, set()\n",
    "\n",
    "async def main():\n",
    "    total_unique_users = set()\n",
    "    summary_df = pd.DataFrame(columns=['channel_name', 'count'])\n",
    "    current_date = start_date\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "\n",
    "        while current_date < end_date:\n",
    "            start_date_integer = int(current_date.strftime('%Y%m%d'))\n",
    "            end_date_integer = int((current_date + timedelta(days=29)).strftime('%Y%m%d'))\n",
    "\n",
    "            tasks.append(fetch_event_data(session, start_date_integer, end_date_integer))\n",
    "            current_date += timedelta(days=30)\n",
    "\n",
    "            if len(tasks) >= 3:  # Limit to 3 concurrent tasks to respect rate limit\n",
    "                results = await asyncio.gather(*tasks)\n",
    "                for event_data, unique_users in results:\n",
    "                    if not event_data:\n",
    "                        print(f\"No data for events from {current_date} to {(current_date + timedelta(days=29))}\")\n",
    "                        continue\n",
    "\n",
    "                    total_unique_users.update(unique_users)\n",
    "                    df = pd.DataFrame(list(event_data.items()), columns=['channel_name', 'count'])\n",
    "                    \n",
    "                    new_rows = []\n",
    "                    for idx, row in df.iterrows():\n",
    "                        channel_names = row['channel_name'].split(', ')\n",
    "                        for name in channel_names:\n",
    "                            new_rows.append({'channel_name': name.strip().lower(), 'count': row['count']})\n",
    "                    new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "                    new_df['channel_name_mapped'] = new_df['channel_name'].apply(lambda name: mapping.get(name, None))\n",
    "                    df_filtered = new_df[new_df['channel_name_mapped'].notnull()]\n",
    "\n",
    "                    result = df_filtered.groupby('channel_name_mapped')['count'].sum().reset_index()\n",
    "                    result.columns = ['channel_name', 'count']\n",
    "\n",
    "                    for column in required_columns:\n",
    "                        if column not in result['channel_name'].values:\n",
    "                            result = pd.concat([result, pd.DataFrame({'channel_name': [column], 'count': [0]})])\n",
    "\n",
    "                    summary_df = pd.concat([summary_df, result])\n",
    "\n",
    "                tasks = []  # Reset tasks\n",
    "\n",
    "        # Process any remaining tasks\n",
    "        if tasks:\n",
    "            results = await asyncio.gather(*tasks)\n",
    "            for event_data, unique_users in results:\n",
    "                if not event_data:\n",
    "                    continue\n",
    "\n",
    "                total_unique_users.update(unique_users)\n",
    "                df = pd.DataFrame(list(event_data.items()), columns=['channel_name', 'count'])\n",
    "\n",
    "                new_rows = []\n",
    "                for idx, row in df.iterrows():\n",
    "                    channel_names = row['channel_name'].split(', ')\n",
    "                    for name in channel_names:\n",
    "                        new_rows.append({'channel_name': name.strip().lower(), 'count': row['count']})\n",
    "                new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "                new_df['channel_name_mapped'] = new_df['channel_name'].apply(lambda name: mapping.get(name, None))\n",
    "                df_filtered = new_df[new_df['channel_name_mapped'].notnull()]\n",
    "\n",
    "                result = df_filtered.groupby('channel_name_mapped')['count'].sum().reset_index()\n",
    "                result.columns = ['channel_name', 'count']\n",
    "\n",
    "                for column in required_columns:\n",
    "                    if column not in result['channel_name'].values:\n",
    "                        result = pd.concat([result, pd.DataFrame({'channel_name': [column], 'count': [0]})])\n",
    "\n",
    "                summary_df = pd.concat([summary_df, result])\n",
    "\n",
    "    # Aggregate the 30 days summary data\n",
    "    summary_df = summary_df.groupby('channel_name')['count'].sum().reset_index()\n",
    "    summary_df['calculated_Date'] = pd.to_datetime(end_date, format='%Y%m%d').date()\n",
    "    calculated_end_date = end_date - timedelta(days=1)\n",
    "    summary_df['start_date_range'] = pd.to_datetime(start_date, format='%Y%m%d').date()\n",
    "    summary_df['end_date_range'] = pd.to_datetime(calculated_end_date, format='%Y%m%d').date()\n",
    "    summary_df['Metric Name'] = '30 - Days Unique Active Users'\n",
    "\n",
    "    for column in required_columns: \n",
    "        if column not in summary_df['channel_name'].values:\n",
    "            summary_df = pd.concat([summary_df, pd.DataFrame({'channel_name': [column], 'count': [0]})])\n",
    "\n",
    "    summary_df.reset_index(drop=True, inplace=True)\n",
    "    summary_df = summary_df[['calculated_Date', 'start_date_range', 'end_date_range', 'Metric Name', 'channel_name', 'count']]\n",
    "    print(summary_df)\n",
    "\n",
    "    # Save the summary to the Excel file\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl', mode='a') as writer:\n",
    "        summary_df.to_excel(writer, index=False, sheet_name='30 Days Summary', header=True)\n",
    "\n",
    "    #print(f\"Total unique users over the 30 days: {len(total_unique_users)}\")\n",
    "\n",
    "# Run the main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
