{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34adb3-f98a-4c37-95a5-62eef03e5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl\n",
    "\n",
    "MAX_RETRIES = 10\n",
    "RETRY_DELAY = 65  # Increase delay between retries to give the server more time to process\n",
    "\n",
    "\n",
    "# Date range for data fetching\n",
    "#start_date = datetime(2024, 7, 26)\n",
    "#end_date = datetime(2024, 7, 28)\n",
    "\n",
    "#Get today's date\n",
    "end_date = datetime.now()\n",
    "\n",
    "#Calculate the start date (1 days before today)\n",
    "start_date = end_date - timedelta(days=1)\n",
    "\n",
    "# Output file for results\n",
    "output_file = r'C:\\Users\\praveen\\Email_Sent_Users.xlsx'\n",
    "\n",
    "\n",
    "# Mapping dictionary for channel names\n",
    "mapping = {\n",
    "    'india': 'India',\n",
    "    'philippines': 'Philippines',\n",
    "    'malaysia': 'Malaysia',\n",
    "    'singapore': 'Singapore',\n",
    "    'gulf': 'Middle East',\n",
    "    'hongkong': 'Hongkong',\n",
    "    'thailand': 'Thailand',\n",
    "    'indonesia': 'Indonesia',\n",
    "    'vietnam': 'Vietnam',\n",
    "    'rexmonster': 'India',\n",
    "}\n",
    "\n",
    "# Required columns for the final result\n",
    "required_columns = [\n",
    "    'India',\n",
    "    'Philippines',\n",
    "    'Malaysia',\n",
    "    'Singapore',\n",
    "    'Middle East',\n",
    "    'Hongkong',\n",
    "    'Thailand',\n",
    "    'Indonesia',\n",
    "    'Vietnam',\n",
    "]\n",
    "\n",
    "# Define the list of events to fetch\n",
    "events = [\"Notification Sent\", \"Email_Sent\", \"Webhook Delivered\"]   # Add your events here\n",
    "\n",
    "\n",
    "# Function to get data for an event\n",
    "def get_event_data(event_name, date_integer):\n",
    "    url = \"https://in1.api.clevertap.com/1/profiles.json\"           #?batch_size=20000\n",
    "    payload = json.dumps({\n",
    "        \"event_name\": event_name,\n",
    "        \"from\": date_integer,\n",
    "        \"to\": date_integer\n",
    "    })\n",
    "    headers = {\n",
    "        'X-CleverTap-Account-Id': '********',\n",
    "        'X-CleverTap-Passcode': '*********',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    retry_count = 0\n",
    "    while retry_count < MAX_RETRIES:\n",
    "        response = requests.post(url, headers=headers, data=payload)\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Handle request still in progress\n",
    "        if response_json.get('status') == 'fail' and response_json.get('code') == 2:\n",
    "            retry_count += 1\n",
    "            print(f\"Request still in progress, please retry later. Retrying... Attempt {retry_count}\")\n",
    "            time.sleep(RETRY_DELAY * retry_count)\n",
    "            continue\n",
    "        elif response_json.get('status') == 'fail':\n",
    "            print(f\"Failed request with error: {response_json.get('error')}\")\n",
    "            return {}\n",
    "\n",
    "        # Process data with cursor pagination\n",
    "        cursor = response_json.get('cursor')\n",
    "        count_country = {}\n",
    "\n",
    "        while cursor:\n",
    "            next_url = f\"https://in1.api.clevertap.com/1/profiles.json?cursor={cursor}\"\n",
    "            response = requests.get(next_url, headers=headers)\n",
    "\n",
    "            try:\n",
    "                response_json = response.json()\n",
    "                cursor = response_json.get('next_cursor')\n",
    "                \n",
    "                # Count events by channel\n",
    "                if 'records' in response_json:\n",
    "                    for record in response_json['records']:\n",
    "                        channel = record.get('profileData', None)\n",
    "                        if channel is not None:\n",
    "                            channel_name = channel.get('channel_name', None)\n",
    "                            if channel_name is not None:\n",
    "                                if isinstance(channel_name, list):\n",
    "                                    channel_name = ', '.join(channel_name)\n",
    "\n",
    "                                if channel_name not in count_country:\n",
    "                                    count_country[channel_name] = 1\n",
    "                                else:\n",
    "                                    count_country[channel_name] += 1\n",
    "                else:\n",
    "                    print(json.dumps(response_json))\n",
    "            except ValueError:\n",
    "                print(response.text)\n",
    "\n",
    "        if count_country:\n",
    "            return count_country\n",
    "        else:\n",
    "            retry_count += 1\n",
    "            print(f\"Retrying... Attempt {retry_count}\")\n",
    "            time.sleep(RETRY_DELAY * retry_count)\n",
    "    print(\"Max retries reached. Unable to fetch data.\")\n",
    "    return {}\n",
    "\n",
    "\n",
    "# Main loop to iterate over dates and events\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    date_integer = int(current_date.strftime('%Y%m%d'))\n",
    "    for event in events:\n",
    "        start_time = time.time()  # Start timer\n",
    "        event_data = get_event_data(event, date_integer)\n",
    "        if not event_data:\n",
    "            print(f\"No data for event {event} on {current_date}\")\n",
    "            current_date += timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        # Convert event data to DataFrame\n",
    "        df = pd.DataFrame(list(event_data.items()), columns=['channel_name', 'count'])\n",
    "        new_rows = []\n",
    "        for idx, row in df.iterrows():\n",
    "            channel_names = row['channel_name'].split(', ')\n",
    "            for name in channel_names:\n",
    "                new_rows.append({'channel_name': name.strip().lower(), 'count': row['count']})\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "        # Map channel names using the mapping dictionary\n",
    "        def map_channel_name(name):\n",
    "            for key in mapping.keys():\n",
    "                if key in name.lower():\n",
    "                    return mapping[key]\n",
    "            return None\n",
    "\n",
    "        new_df['channel_name_mapped'] = new_df['channel_name'].apply(map_channel_name)\n",
    "\n",
    "        \n",
    "        # Filter and group the data\n",
    "        df_filtered = new_df[new_df['channel_name_mapped'].notnull()]\n",
    "        result = df_filtered.groupby('channel_name_mapped')['count'].sum().reset_index()\n",
    "        result.columns = ['channel_name', 'count']\n",
    "        result['event_name'] = event  # Add the event name to the result\n",
    "\n",
    "        # Ensure all required columns are present\n",
    "        for column in required_columns:\n",
    "            if column not in result['channel_name'].values:\n",
    "                result = pd.concat([result, pd.DataFrame({'channel_name': [column], 'count': [0], 'event_name': [event]})])\n",
    "\n",
    "        result['Date'] = pd.to_datetime(current_date, format='%Y%m%d').date()\n",
    "\n",
    "        result.reset_index(drop=True, inplace=True)\n",
    "        result = result[['Date', 'event_name', 'channel_name', 'count']]\n",
    "\n",
    "        end_time = time.time()  # End timer\n",
    "        execution_time = end_time - start_time  # Calculate execution time\n",
    "\n",
    "        print(result)\n",
    "        print(f\"Execution time for {event} on {current_date}: {execution_time:.2f} seconds\")\n",
    "\n",
    "        # Append results to Excel file\n",
    "        try:\n",
    "            with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "                book = writer.book\n",
    "                if 'Event_Data' in book.sheetnames:\n",
    "                    existing_data = pd.read_excel(output_file, sheet_name='Event_Data')\n",
    "                    if 'Date' not in existing_data.columns:\n",
    "                        raise KeyError(\"'Date' column is missing in the existing data\")\n",
    "                    if 'event_name' not in existing_data.columns:\n",
    "                        existing_data['event_name'] = None\n",
    "                    existing_data['Date'] = pd.to_datetime(existing_data['Date'])\n",
    "                    \n",
    "                    # Ensure uniqueness in existing_data\n",
    "                    existing_data = existing_data.drop_duplicates(subset=['Date', 'event_name', 'channel_name'])\n",
    "                    result = result.drop_duplicates(subset=['Date', 'event_name', 'channel_name'])\n",
    "                    updated_data = pd.concat([existing_data, result], ignore_index=True)\n",
    "                    updated_data.to_excel(writer, sheet_name='Event_Data', index=False)\n",
    "                else:\n",
    "                    result.to_excel(writer, sheet_name='Event_Data', index=False)\n",
    "        except FileNotFoundError:\n",
    "            with pd.ExcelWriter(output_file, mode='w', engine='openpyxl') as writer:\n",
    "                result.to_excel(writer, sheet_name='Event_Data', index=False)\n",
    "\n",
    "    current_date += timedelta(days=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
